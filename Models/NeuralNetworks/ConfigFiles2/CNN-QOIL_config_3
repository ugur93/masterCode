########### LAYER CONFIG ########### 

Main_input -> gaussiannoise_1 -> convolution1d_1 -> averagepooling1d_1 -> dropout_1 -> dense_1 -> flatten_1 -> MAIN_OUT
['Main_input', {'name': 'gaussiannoise_1', 'sigma': 0.01, 'trainable': True}, {'activity_regularizer': None, 'trainable': True, 'init': 'glorot_uniform', 'subsample_length': 1, 'W_constraint': None, 'b_constraint': None, 'bias': True, 'activation': 'relu', 'input_dim': None, 'filter_length': 2, 'W_regularizer': None, 'name': 'convolution1d_1', 'nb_filter': 32, 'b_regularizer': None, 'input_length': None, 'border_mode': 'same'}, {'name': 'averagepooling1d_1', 'pool_length': 1, 'trainable': True, 'stride': 1, 'border_mode': 'valid'}, {'name': 'dropout_1', 'trainable': True, 'p': 0.01}, {'activity_regularizer': None, 'trainable': True, 'W_constraint': None, 'b_constraint': None, 'bias': True, 'b_regularizer': None, 'init': 'glorot_uniform', 'input_dim': 32, 'name': 'dense_1', 'W_regularizer': {'name': 'L1L2Regularizer', 'l1': 0.0, 'l2': 9.999999747378752e-05}, 'output_dim': 20, 'activation': 'relu'}, {'name': 'flatten_1', 'trainable': True}, {'activity_regularizer': None, 'trainable': True, 'W_constraint': None, 'b_constraint': None, 'bias': True, 'b_regularizer': None, 'init': 'glorot_uniform', 'input_dim': 20, 'name': 'MAIN_OUT', 'W_regularizer': {'name': 'L1L2Regularizer', 'l1': 0.0, 'l2': 9.999999747378752e-05}, 'output_dim': 7, 'activation': 'linear'}]

----------------------------------- 
##### CHK thresholds ##### 
----------------------------------- 
C1: 0.05
B1: 0.05
C2: 0.05
B3: 0.05
D1: 0.05
C4: 0.05
C3: 0.05
----------------------------------- 
##### OUTPUT INDEX ##### 
----------------------------------- 
C2_PDC: 1
C1_PDC: 0
C4_PDC: 3
D1_PDC: 6
C3_PDC: 2
B3_PDC: 5
B1_PDC: 4
-------------------------------------------------
##### Input-module config ##### 
-------------------------------------------------
- n_depth: 2 
- n_width: 20 
- n_inception: 0 
- l2_weight: 0.0001 
- OnOff_state: True 
- Initialization: glorot_uniform 
-------------------------------------------------
##### Fit config ##### 
------------------------------------------------- 
- epoch: 10000 
- batch size: 64 
- verbose: 0 
- callbacks: [<Models.NeuralNetworks.base.LossHistory object at 0x7f848d5b0358>, <Models.NeuralNetworks.base.EpochVerbose object at 0x7f848d5585f8>, <keras.callbacks.EarlyStopping object at 0x7f848d5b0e48>] 
- optimizer: adam 
-------------------------------------------------
##### Input tags ##### 
-------------------------------------------------
Main_input: ['C1_CHK', 'C2_CHK', 'C3_CHK', 'C4_CHK', 'B1_CHK', 'B3_CHK', 'D1_CHK']
-------------------------------------------------
##### Output tags ##### 
 -------------------------------------------------
MAIN_OUT: ['C1_PDC', 'C2_PDC', 'C3_PDC', 'C4_PDC', 'B1_PDC', 'B3_PDC', 'D1_PDC']
-------------------------------------------------
-------------------------------------------------

                 #### Scores #### 
RMSE TRAIN:                   RMSE VAL:                     Percentage error (VAL/MEAN)*100         MEAN
------------------------------------------------------------------------------------------------------------------------
C1_PDC: 3.08                  C1_PDC: 11.53                 C1_PDC: 17.45%                          C1_PDC: 66.06
C2_PDC: 3.08                  C2_PDC: 11.51                 C2_PDC: 17.43%                          C2_PDC: 66.04
C3_PDC: 3.08                  C3_PDC: 11.55                 C3_PDC: 17.47%                          C3_PDC: 66.14
C4_PDC: 3.07                  C4_PDC: 11.48                 C4_PDC: 17.33%                          C4_PDC: 66.27
B1_PDC: 3.54                  B1_PDC: 11.62                 B1_PDC: 17.66%                          B1_PDC: 65.79
B3_PDC: 3.11                  B3_PDC: 11.72                 B3_PDC: 17.87%                          B3_PDC: 65.60
D1_PDC: 3.08                  D1_PDC: 11.58                 D1_PDC: 17.50%                          D1_PDC: 66.20
-------------------------------------------------------
R2 TRAIN:                     R2 VAL: 
-------------------------------------------------------
C1_PDC: 0.66                  C1_PDC: -3.19
C2_PDC: 0.66                  C2_PDC: -3.17
C3_PDC: 0.66                  C3_PDC: -3.22
C4_PDC: 0.67                  C4_PDC: -3.16
B1_PDC: 0.60                  B1_PDC: -3.39
B3_PDC: 0.66                  B3_PDC: -3.30
D1_PDC: 0.67                  D1_PDC: -3.27
-------------------------------------------------------
#### ------ #### 
